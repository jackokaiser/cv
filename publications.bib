@conference{kaiser2018hmax,
author={Jacques Kaiser and Gerd Lindner and J. Camilo Vasquez Tieck and Martin Schulze and Michael Hoff and Arne Roennau and R\"udiger Dillmann},
title={Microsaccades for asynchronous feature extraction with spiking networks},
booktitle={International Conference on Development and Learning and Epigenetic Robotics (ICDL-EPIROB)},
organization = {IEEE},
year={2018}
}

@conference{kaiser2018stereo,
author={Jacques Kaiser and Jakob Weinland and Philip Keller and J. Camilo Vasquez Tieck and Timothee B\"uttner and Daniel Reichard and Arne Roennau and R\"udiger Dillmann},
title={Microsaccades for Event-Based Stereo Vision with Spiking Neural Networks},
booktitle={International Conference on Artificial Neural Networks (ICANN)},
year={2018},
}

@inproceedings{kaiser2018il,
  title = {Learning to reproduce visually similar movements by minimizing event-based prediction error},
  author = {Jacques Kaiser and Svenja Melbaum and J. Camilo Vasquez Tieck and Arne Roennau and Martin V. Butz and Rüdiger Dillmann},
  booktitle = {International Conference on Biomedical Robotics and Biomechatronics (BIOROB)},
  publisher={IEEE},
  year={2018},
  abstract={
  Prediction is believed to play an important role in the human brain.
  However, it is still unclear how predictions are used in the process of learning new movements.
  In this paper, we present a method to learn movements from visual prediction.
  The method consists of two phases: learning a visual prediction model for a given movement, then minimizing the visual prediction error.
  The visual prediction model is learned from a single demonstration of the movement where only visual input is sensed.
  Unlike previous work, we represent visual information with event streams as provided by a Dynamic Vision Sensor.
  This allows us to only process changes in the environment instead of complete snapshots using spiking neural networks.
  By minimizing the prediction error, movements visually similar to the demonstration are learned.
  We evaluate our method by learning simple movements from human demonstrations on different simulated robots.
  We show that the definition of the visual prediction error greatly impacts movements learned by our method.
  }
}

@inproceedings{kaiser2018ilAbstract,
  title = {Learning Movements by Imitation from Event-Based Visual Prediction},
  note = {(Extended Abstract)},
  author = {Jacques Kaiser and Rüdiger Dillmann},
  booktitle = {2\textsuperscript{nd} Human Brain Project Student Conference},
  year = {2018}
}


@inproceedings{kaiser2017spiking,
  title={Spiking convolutional deep belief networks},
  author={Kaiser, Jacques and Zimmerer, David and Tieck, J Camilo Vasquez and Ulbrich, Stefan and Roennau, Arne and Dillmann, R{\"u}diger},
  booktitle={International Conference on Artificial Neural Networks (ICANN)},
  pages={3--11},
  year={2017},
  organization={Springer}
}

@article{our-lsm,
  author={Jacques Kaiser and Rainer Stal and Anand Subramoney and Arne Roennau and Rüdiger Dillmann},
  title={Scaling up liquid state machines to predict over address events from dynamic vision sensors},
  journal={Bioinspiration \& Biomimetics},
  volume={12},
  number={5},
  pages={055001},
  url={http://stacks.iop.org/1748-3190/12/i=5/a=055001},
  year={2017}
}


@InProceedings{Kaiser2016a,
  author       = {Kaiser, Jacques and Tieck, J Camilo Vasquez and Hubschneider, Christian and Wolf, Peter and Weber, Michael and Hoff, Michael and Friedrich, Alexander and Wojtasik, Konrad and Roennau, Arne and Kohlhaas, Ralf and others},
  title        = {Towards a framework for end-to-end control of a simulated vehicle with spiking neural networks},
  booktitle    = {International Conference on Simulation, Modeling, and Programming for Autonomous Robots (SIMPAR)},
  year         = {2016},
  pages        = {127--134},
  organization = {IEEE},
  file         = {:literature/Towards a framework for end-to-end control of a simulated vehicle with spiking neural networks.pdf:PDF},
  review       = {- motivation: it is yet unclear how to train SNNs to solve complex problems
- 1. contribution: framework for evaluation of neural self-driving vehicle applications
- 2. contribution: a SNN for end-to-end (input to steering wheel) lane following behavior},
}
